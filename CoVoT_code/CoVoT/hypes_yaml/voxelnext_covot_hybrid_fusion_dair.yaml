name: voxelnext_covot_intermediate_with_res_DAIR
data_dir: "/home/ubuntu/Datasets/DAIR-V2X/DAIR-V2X-C/cooperative-vehicle-infrastructure/"
split_dir: "/home/ubuntu/Projects/DAIR-V2X/data/split_datas/cooperative-split-data.json"
trainclass:
  "all" # all, Car
alignment:
  0

noise_setting:
  add_noise: False
  args: 
    pos_std: 0 #10
    rot_std: 0
    pos_mean: 0
    rot_mean: 0

yaml_parser: "load_second_params"
train_params:
  batch_size: &batch_size 8
  epoches: 50
  eval_freq: 1
  save_freq: 1

fusion:
  core_method: 'HybridFusionDatasetDAIR' # LateFusionDataset, EarlyFusionDataset, IntermediateFusionDataset supported
  args: 
    proj_first: false
    clip_pc: false

# preprocess-related
preprocess:
  # options: BasePreprocessor, VoxelPreprocessor, BevPreprocessor
  core_method: 'SpVoxelPreprocessor'
  args:
    voxel_size: &voxel_size [0.08, 0.08, 0.1]
    max_points_per_voxel: 4
    max_voxel_train:  60000
    max_voxel_test: 100000
  # lidar range for each individual cav.
  cav_lidar_range: &cav_lidar [0, -46.08, -3, 92.16, 46.08, 1]
  grid_size: &grid_size [1152, 1152, 40]

data_augment:
  - NAME: random_world_flip
    ALONG_AXIS_LIST: [ 'x' ]

  - NAME: random_world_rotation
    WORLD_ROT_ANGLE: [ -0.78539816, 0.78539816 ]

  - NAME: random_world_scaling
    WORLD_SCALE_RANGE: [ 0.95, 1.05 ]

# anchor box related
postprocess:
  core_method: 'VoxelPostprocessor' # VoxelPostprocessor, BevPostprocessor supported
  anchor_args:
    cav_lidar_range: *cav_lidar
    l: 3.9
    w: 1.6
    h: 1.56
    r: [0, 90]
    feature_stride: 8
    num: &achor_num 2
  target_args:
    pos_threshold: 0.6
    neg_threshold: 0.45
    score_threshold: 0.20
  order: 'hwl' # hwl or lwh
  max_num: 100 # maximum number of objects in a single frame. use this number to make sure different frames has the same dimension in the same batch
  nms_thresh: 0.15

# model related
model:
  core_method: voxelnext_covot_hybrid
  args:
    raw: false
    backbone_fix: true
    batch_size: *batch_size
    voxel_size: *voxel_size
    lidar_range: *cav_lidar
    anchor_number: *achor_num
    anchor_num: *achor_num
    grid_size: *grid_size
    mean_vfe:
      feature_points: &num_point_features 4

    # pruning:
    #   input_channels: *num_point_features
    #   grid_size: *grid_size
    #   spconv_kernel_sizes: [3, 3, 3]
    #   channels: [32, 64, 128]
    #   point_cloud_range: *cav_lidar
    #   # downsample_pruning_ratio: [0.5,]
    # pruning_ratio: [[0.5],[0.5],[0.5],[0.5]] # for serial pruning
    
    backbone_3d:
      input_channels: *num_point_features
      grid_size: *grid_size
      spconv_kernel_sizes: [3, 3, 3, 3, 3]
      channels: [32, 64, 128, 256, 256]
      out_channel: 256
      point_cloud_range: *cav_lidar

    fusion:
      d_model: [256, 256]
      nhead: [8, 8]
      num_blocks: 2
      dim_feedforward: [256, 256]
      vote_channel: [256, 128, 64]
      fusion_channel: [512, 384, 256]
      output_shape: [144, 144] #ny nx
      pruning_ratio: 0.5
      debug: true
      encoder:
        window_shape: [8, 8]
        sparse_shape: [144, 144, 1]
        shuffle_voxels: true
        debug: true
        # drop_info: # directly in function
        pos_temperature: 10000
        normalize_pos: false

    base_bev_backbone:
      layer_nums: [5, 5]
      layer_strides: [1, 2]
      num_filters: [128, 256]
      upsample_strides: [1, 2]
      num_upsample_filter: [256, 256]
    preprocess:
    # options: BasePreprocessor, VoxelPreprocessor, BevPreprocessor
      core_method: 'SpVoxelPreprocessorGPU'
      args:
        voxel_size: *voxel_size
        max_points_per_voxel: 4
        max_voxel_train: 60000
        max_voxel_test: 100000
      # lidar range for each individual cav.
      cav_lidar_range: *cav_lidar
      grid_size: *grid_size
    quant_level: [*voxel_size,[0.1, 0.1, 0.1]]
    point_cloud_range: *cav_lidar
    quantize_switch: false

loss:
  core_method: point_pillar_loss
  args:
    cls_weight: 1.0
    reg: 2.0

optimizer:
  core_method: AdamW
  lr: 0.0002
  args:
    eps: 1e-10
    weight_decay: 1e-4

lr_scheduler:
  core_method: multistep #step, multistep and Exponential support
  gamma: 0.1
  step_size: [20, 40, 80]


